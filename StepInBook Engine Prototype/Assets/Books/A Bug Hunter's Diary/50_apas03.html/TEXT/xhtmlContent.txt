<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>A.3 Type Conversions in C</title><link rel="stylesheet" href="core.css" type="text/css"/><meta name="generator" content="DocBook XSL Stylesheets V1.74.0"/></head><body><div class="sect1" title="A.3 Type Conversions in C"><div class="titlepage"><div><div><h1 class="title"><a id="a.3_type_conversions_in_c"/>A.3 Type Conversions in C</h1></div></div></div><p>The C programming language is quite flexible in handling different data types. For example, in C it’s easy to convert a character array into a signed integer. There are two types of conversion: <span class="emphasis"><em>implicit</em></span> and <span class="emphasis"><em>explicit</em></span>. In programming languages like C, implicit type conversion occurs when the compiler automatically converts a variable to a different type. This usually happens when the initial variable type is incompatible with the operation you are trying to perform. Implicit type conversions are also referred to as <span class="emphasis"><em>coercion</em></span>.<a id="IDX-APP-A-0049" class="indexterm"/></p><p>Explicit type conversion, also known as <span class="emphasis"><em>casting</em></span>, occurs when the programmer explicitly codes the details of the conversion. This is usually done with the cast operator.</p><p>Here is an example of an implicit type conversion (coercion):</p><a id="I_programlisting_d1e10061"/><pre class="programlisting">[..]
unsigned int user_input = 0x80000000;
signed int   length     = user_input;
[..]</pre><p>In this example, an implicit conversion occurs between unsigned int and signed int.</p><p>And here is an example of an explicit type conversion (casting):<a id="IDX-APP-A-0050" class="indexterm"/></p><a id="I_programlisting_d1e10070"/><pre class="programlisting">[..]
char       cbuf[] = "AAAA";
signed int si     = *(int *)cbuf;
[..]</pre><p>In this example, an explicit conversion occurs between char and signed int.</p><p>Type conversions can be very subtle and cause a lot of security bugs. Many of the vulnerabilities related to type conversion are the result of conversions between unsigned and signed integers. Below is an example:</p><div class="example"><a id="a_signed_solidus_unsigned_conversion"/><p class="title">Example A-3. A signed/unsigned conversion that leads to a vulnerability (<span class="emphasis"><em>implicit.c</em></span>)</p><div class="example-contents"><pre class="programlisting">01    #include &lt;stdio.h&gt;
02
03    unsigned int
04    get_user_length (void)
05    {
06        return (0xffffffff);
07    }
08
09    int
10    main (void)
11    {
12        signed int length = 0;
13
14        length = get_user_length ();
15
16        printf ("length: %d %u (0x%x)\n", length, length, length);
17
18        if (length &lt; 12)
19            printf ("argument length ok\n");
20        else
21            printf ("Error: argument length too long\n");
22
23        return 0;
24    }</pre></div></div><p>The source code in <a class="xref" href="apas03.html#a_signed_solidus_unsigned_conversion" title="Example A-3. A signed/unsigned conversion that leads to a vulnerability (implicit.c)">Example A-3</a> contains a signed/unsigned conversion vulnerability that is quite similar to the one I found in FFmpeg (see <a class="xref" href="ch04.html" title="Chapter 4. NULL Pointer FTW">Chapter 4</a>). Can you spot the bug?</p><p>In line 14, a length value is read in from user input and stored in the signed int variable <code class="literal">length</code>. The <code class="literal">get_user_length()</code> function is a dummy that always returns the “user input value” <code class="literal">0xffffffff</code>. Let’s assume this is the value that was read from the network or from a data file. In line 18, the program checks whether the user-supplied value is less than 12. If it is, the string “<code class="literal">argument length ok</code>” will be printed on the screen. Since <code class="literal">length</code> gets assigned the value <code class="literal">0xffffffff</code> and this value is much bigger than 12, it may seem obvious that the string will not be printed. However, let’s see what happens if we compile and run the program under Windows Vista SP2:<a id="IDX-APP-A-0051" class="indexterm"/><a id="IDX-APP-A-0052" class="indexterm"/></p><a id="I_programlisting_d1e10118"/><pre class="programlisting">C:\Users\tk\BHD&gt;<strong class="userinput"><code>cl /nologo implicit.c</code></strong>
implicit.c

C:\Users\tk\BHD&gt;<strong class="userinput"><code>implicit.exe</code></strong>
length: −1 4294967295 (0xffffffff)
argument length ok</pre><p>As you can see from the output, line 19 was reached and executed. How did this happen?</p><p>On a 32-bit machine, an unsigned int has a range of 0 to 4294967295 and a signed int has a range of –2147483648 to 2147483647. The unsigned int value <code class="literal">0xffffffff</code> (4294967295) is represented in binary as <code class="literal">1111 1111 1111 1111 1111 1111 1111 1111</code> (see <a class="xref" href="apas03.html#the_role_of_the_most_significant_bit_ope" title="Figure A-3. The role of the Most Significant Bit (MSB)">Figure A-3</a>). If you interpret the same bit pattern as a signed int, there is a change in sign that results in a signed int value of −1. The sign of a number is indicated by the <span class="emphasis"><em>sign bit</em></span>, which is usually represented by the <span class="emphasis"><em>Most Significant Bit (MSB)</em></span>. If the MSB is 0, the number is positive, and if it is set to 1, the number is negative.<a id="IDX-APP-A-0053" class="indexterm"/><a id="IDX-APP-A-0054" class="indexterm"/></p><div class="figure"><a id="the_role_of_the_most_significant_bit_ope"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject_d1e10154"/><img src="httpatomoreillycomsourcenostarchimages939341.png.jpg" alt="The role of the Most Significant Bit (MSB)"/></div></div><p class="title">Figure A-3. The role of the Most Significant Bit (MSB)</p></div><p>To summarize: If an unsigned int is converted to a signed int value, the bit pattern isn’t changed, but the value is interpreted in the context of the new type. If the unsigned int value is in the range <code class="literal">0x80000000</code> to <code class="literal">0xffffffff</code>, the resulting signed int will become negative (see <a class="xref" href="apas03.html#integer_type_conversion_colon_unsigned_i" title="Figure A-4. Integer type conversion: unsigned int to signed int">Figure A-4</a>).</p><p>This was only a brief introduction to implicit and explicit type conversions in C/C++. For a complete description of type conversions in C/C++ and associated security problems, see Mark Dowd, John McDonald, and Justin Schuh’s <span class="emphasis"><em>The Art of Software Security Assessment: Identifying and Avoiding Software Vulnerabilities</em></span> (Addison-Wesley, 2007).<a id="IDX-APP-A-0055" class="indexterm"/><a id="IDX-APP-A-0056" class="indexterm"/></p><div class="figure"><a id="integer_type_conversion_colon_unsigned_i"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject_d1e10183"/><img src="httpatomoreillycomsourcenostarchimages939343.png.jpg" alt="Integer type conversion: unsigned int to signed int"/></div></div><p class="title">Figure A-4. Integer type conversion: unsigned int to signed int</p></div><div class="note" title="Note"><h3 class="title">Note</h3><p><span class="emphasis"><em>I used Debian Linux 6.0 (32-bit) as a platform for all the following steps</em></span>.<a id="IDX-APP-A-0057" class="indexterm"/><a id="IDX-APP-A-0058" class="indexterm"/></p></div></div></body></html>
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>A.3 Type Conversions in C</title><link rel="stylesheet" href="core.css" type="text/css"/><meta name="generator" content="DocBook XSL Stylesheets V1.74.0"/></head><body><div class="sect1" title="A.3 Type Conversions in C"><div class="titlepage"><div><div><h1 class="title"><a id="a.3_type_conversions_in_c"/>A.3 Type Conversions in C</h1></div></div></div><p>The C programming language is quite flexible in handling different data types. For example, in C it’s easy to convert a character array into a signed integer. There are two types of conversion: <span class="emphasis"><em>implicit</em></span> and <span class="emphasis"><em>explicit</em></span>. In programming languages like C, implicit type conversion occurs when the compiler automatically converts a variable to a different type. This usually happens when the initial variable type is incompatible with the operation you are trying to perform. Implicit type conversions are also referred to as <span class="emphasis"><em>coercion</em></span>.<a id="IDX-APP-A-0049" class="indexterm"/></p><p>Explicit type conversion, also known as <span class="emphasis"><em>casting</em></span>, occurs when the programmer explicitly codes the details of the conversion. This is usually done with the cast operator.</p><p>Here is an example of an implicit type conversion (coercion):</p><a id="I_programlisting_d1e10061"/><pre class="programlisting">[..]
unsigned int user_input = 0x80000000;
signed int   length     = user_input;
[..]</pre><p>In this example, an implicit conversion occurs between unsigned int and signed int.</p><p>And here is an example of an explicit type conversion (casting):<a id="IDX-APP-A-0050" class="indexterm"/></p><a id="I_programlisting_d1e10070"/><pre class="programlisting">[..]
char       cbuf[] = "AAAA";
signed int si     = *(int *)cbuf;
[..]</pre><p>In this example, an explicit conversion occurs between char and signed int.</p><p>Type conversions can be very subtle and cause a lot of security bugs. Many of the vulnerabilities related to type conversion are the result of conversions between unsigned and signed integers. Below is an example:</p><div class="example"><a id="a_signed_solidus_unsigned_conversion"/><p class="title">Example A-3. A signed/unsigned conversion that leads to a vulnerability (<span class="emphasis"><em>implicit.c</em></span>)</p><div class="example-contents"><pre class="programlisting">01    #include &lt;stdio.h&gt;
02
03    unsigned int
04    get_user_length (void)
05    {
06        return (0xffffffff);
07    }
08
09    int
10    main (void)
11    {
12        signed int length = 0;
13
14        length = get_user_length ();
15
16        printf ("length: %d %u (0x%x)\n", length, length, length);
17
18        if (length &lt; 12)
19            printf ("argument length ok\n");
20        else
21            printf ("Error: argument length too long\n");
22
23        return 0;
24    }</pre></div></div><p>The source code in <a class="xref" href="apas03.html#a_signed_solidus_unsigned_conversion" title="Example A-3. A signed/unsigned conversion that leads to a vulnerability (implicit.c)">Example A-3</a> contains a signed/unsigned conversion vulnerability that is quite similar to the one I found in FFmpeg (see <a class="xref" href="ch04.html" title="Chapter 4. NULL Pointer FTW">Chapter 4</a>). Can you spot the bug?</p><p>In line 14, a length value is read in from user input and stored in the signed int variable <code class="literal">length</code>. The <code class="literal">get_user_length()</code> function is a dummy that always returns the “user input value” <code class="literal">0xffffffff</code>. Let’s assume this is the value that was read from the network or from a data file. In line 18, the program checks whether the user-supplied value is less than 12. If it is, the string “<code class="literal">argument length ok</code>” will be printed on the screen. Since <code class="literal">length</code> gets assigned the value <code class="literal">0xffffffff</code> and this value is much bigger than 12, it may seem obvious that the string will not be printed. However, let’s see what happens if we compile and run the program under Windows Vista SP2:<a id="IDX-APP-A-0051" class="indexterm"/><a id="IDX-APP-A-0052" class="indexterm"/></p><a id="I_programlisting_d1e10118"/><pre class="programlisting">C:\Users\tk\BHD&gt;<strong class="userinput"><code>cl /nologo implicit.c</code></strong>
implicit.c

C:\Users\tk\BHD&gt;<strong class="userinput"><code>implicit.exe</code></strong>
length: −1 4294967295 (0xffffffff)
argument length ok</pre><p>As you can see from the output, line 19 was reached and executed. How did this happen?</p><p>On a 32-bit machine, an unsigned int has a range of 0 to 4294967295 and a signed int has a range of –2147483648 to 2147483647. The unsigned int value <code class="literal">0xffffffff</code> (4294967295) is represented in binary as <code class="literal">1111 1111 1111 1111 1111 1111 1111 1111</code> (see <a class="xref" href="apas03.html#the_role_of_the_most_significant_bit_ope" title="Figure A-3. The role of the Most Significant Bit (MSB)">Figure A-3</a>). If you interpret the same bit pattern as a signed int, there is a change in sign that results in a signed int value of −1. The sign of a number is indicated by the <span class="emphasis"><em>sign bit</em></span>, which is usually represented by the <span class="emphasis"><em>Most Significant Bit (MSB)</em></span>. If the MSB is 0, the number is positive, and if it is set to 1, the number is negative.<a id="IDX-APP-A-0053" class="indexterm"/><a id="IDX-APP-A-0054" class="indexterm"/></p><div class="figure"><a id="the_role_of_the_most_significant_bit_ope"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject_d1e10154"/><img src="httpatomoreillycomsourcenostarchimages939341.png.jpg" alt="The role of the Most Significant Bit (MSB)"/></div></div><p class="title">Figure A-3. The role of the Most Significant Bit (MSB)</p></div><p>To summarize: If an unsigned int is converted to a signed int value, the bit pattern isn’t changed, but the value is interpreted in the context of the new type. If the unsigned int value is in the range <code class="literal">0x80000000</code> to <code class="literal">0xffffffff</code>, the resulting signed int will become negative (see <a class="xref" href="apas03.html#integer_type_conversion_colon_unsigned_i" title="Figure A-4. Integer type conversion: unsigned int to signed int">Figure A-4</a>).</p><p>This was only a brief introduction to implicit and explicit type conversions in C/C++. For a complete description of type conversions in C/C++ and associated security problems, see Mark Dowd, John McDonald, and Justin Schuh’s <span class="emphasis"><em>The Art of Software Security Assessment: Identifying and Avoiding Software Vulnerabilities</em></span> (Addison-Wesley, 2007).<a id="IDX-APP-A-0055" class="indexterm"/><a id="IDX-APP-A-0056" class="indexterm"/></p><div class="figure"><a id="integer_type_conversion_colon_unsigned_i"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject_d1e10183"/><img src="httpatomoreillycomsourcenostarchimages939343.png.jpg" alt="Integer type conversion: unsigned int to signed int"/></div></div><p class="title">Figure A-4. Integer type conversion: unsigned int to signed int</p></div><div class="note" title="Note"><h3 class="title">Note</h3><p><span class="emphasis"><em>I used Debian Linux 6.0 (32-bit) as a platform for all the following steps</em></span>.<a id="IDX-APP-A-0057" class="indexterm"/><a id="IDX-APP-A-0058" class="indexterm"/></p></div></div></body></html>
