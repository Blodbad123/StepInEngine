<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>1.2 Common Techniques</title><link rel="stylesheet" href="core.css" type="text/css"/><meta name="generator" content="DocBook XSL Stylesheets V1.74.0"/></head><body><div class="sect1" title="1.2 Common Techniques"><div class="titlepage"><div><div><h1 class="title"><a id="common_techniques"/>1.2 Common Techniques</h1></div></div></div><p>Although no formal documentation exists that describes the standard bug-hunting process, common techniques do exist. These techniques can be split into two categories: <span class="emphasis"><em>static</em></span> and <span class="emphasis"><em>dynamic</em></span>. In static analysis, also referred to as <span class="emphasis"><em>static code analysis</em></span>, the source code of the software, or the disassembly of a binary, is examined but not executed. Dynamic analysis, on the other hand, involves debugging or fuzzing the target software while it’s executing. Both techniques have pros and cons, and most bug hunters use a combination of static and dynamic techniques.<a id="IDX-CHP-1-0003" class="indexterm"/><a id="IDX-CHP-1-0004" class="indexterm"/><a id="IDX-CHP-1-0005" class="indexterm"/></p><div class="sect2" title="My Preferred Techniques"><div class="titlepage"><div><div><h2 class="title"><a id="my_preferred_techniques"/>My Preferred Techniques</h2></div></div></div><p>Most of the time, I prefer the static analysis approach. I usually read the source code or disassembly of the target software line by line and try to understand it. However, reading all the code from beginning to end is generally not practical. When I’m looking for bugs, I typically start by trying to identify where user-influenced input data enters the software through an interface to the outside world. This could be network data, file data, or data from the execution environment, to name just a few examples.</p><p>Next, I study the different ways that the input data can travel through the software, while looking for any potentially exploitable code that acts on the data. Sometimes I’m able to identify these entry points solely by reading the source code (see <a class="xref" href="ch02.html" title="Chapter 2. Back to the ’90s">Chapter 2</a>) or the disassembly (see <a class="xref" href="ch06.html" title="Chapter 6. One Kernel to Rule Them All">Chapter 6</a>). In other cases, I have to combine static analysis with the results of debugging the target software (see <a class="xref" href="ch05.html" title="Chapter 5. Browse and You’re Owned">Chapter 5</a>) to find the input-handling code. I also tend to combine static and dynamic approaches when developing an exploit.</p><p>After I’ve found a bug, I want to prove if it’s actually exploitable, so I attempt to build an exploit for it. When I build such an exploit, I spend most of my time in the debugger.</p></div><div class="sect2" title="Potentially Vulnerable Code Locations"><div class="titlepage"><div><div><h2 class="title"><a id="potentially_vulnerable_code_locations"/>Potentially Vulnerable Code Locations</h2></div></div></div><p>This is only one approach to bug hunting. Another tactic for finding potentially vulnerable locations in the code is to look at the code near “unsafe” C/C++ library functions, such as <code class="literal">strcpy()</code> and <code class="literal">strcat()</code>, in search of possible buffer overflows. Alternatively, you could search the disassembly for <code class="literal">movsx</code> assembler instructions in order to find sign-extension vulnerabilities. If you find a potentially vulnerable code location, you can then trace backward through the code to see whether these code fragments expose any vulnerabilities accessible from an application entry point. I rarely use this approach, but other bug hunters swear by it.<a id="IDX-CHP-1-0006" class="indexterm"/><a id="IDX-CHP-1-0007" class="indexterm"/><a id="IDX-CHP-1-0008" class="indexterm"/></p></div><div class="sect2" title="Fuzzing"><div class="titlepage"><div><div><h2 class="title"><a id="fuzzing"/>Fuzzing</h2></div></div></div><p>A completely different approach to bug hunting is known as <span class="emphasis"><em>fuzzing</em></span>. Fuzzing is a dynamic-analysis technique that consists of testing an application by providing it with malformed or unexpected input. Though I’m not an expert in fuzzing and fuzzing frameworks—I know bug hunters who have developed their own fuzzing frameworks and find most of their bugs with their fuzzing tools—I do use this approach from time to time to determine where user-influenced input enters the software and sometimes to find bugs (see <a class="xref" href="ch08.html" title="Chapter 8. The Ringtone Massacre">Chapter 8</a>).</p><p>You may be wondering how fuzzing can be used to identify where user-influenced input enters the software. Imagine you have a complex application in the form of a binary that you want to examine for bugs. It isn’t easy to identify the entry points of such complex applications, but complex software often tends to crash while processing malformed input data. This can hold true for software that parses data files, such as office products, media players, or web browsers. Most of these crashes are not security relevant (e.g., a division-by-zero bug in a browser), but they often provide an entry point where I can start looking for user-influenced input data.</p></div><div class="sect2" title="Further Reading"><div class="titlepage"><div><div><h2 class="title"><a id="further_reading"/>Further Reading</h2></div></div></div><p>These are only a few of the available techniques and approaches that can be used to find bugs in software. For more information on finding security vulnerabilities in source code, I recommend Mark Dowd, John McDonald, and Justin Schuh’s <span class="emphasis"><em>The Art of Software Security Assessment: Identifying and Preventing Software Vulnerabilities</em></span> (Addison-Wesley, 2007). If you want more information about fuzzing, see Michael Sutton, Adam Greene, and Pedram Amini’s <span class="emphasis"><em>Fuzzing: Brute Force Vulnerability Discovery</em></span> (Addison-Wesley, 2007).</p></div></div></body></html>
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>1.2 Common Techniques</title><link rel="stylesheet" href="core.css" type="text/css"/><meta name="generator" content="DocBook XSL Stylesheets V1.74.0"/></head><body><div class="sect1" title="1.2 Common Techniques"><div class="titlepage"><div><div><h1 class="title"><a id="common_techniques"/>1.2 Common Techniques</h1></div></div></div><p>Although no formal documentation exists that describes the standard bug-hunting process, common techniques do exist. These techniques can be split into two categories: <span class="emphasis"><em>static</em></span> and <span class="emphasis"><em>dynamic</em></span>. In static analysis, also referred to as <span class="emphasis"><em>static code analysis</em></span>, the source code of the software, or the disassembly of a binary, is examined but not executed. Dynamic analysis, on the other hand, involves debugging or fuzzing the target software while it’s executing. Both techniques have pros and cons, and most bug hunters use a combination of static and dynamic techniques.<a id="IDX-CHP-1-0003" class="indexterm"/><a id="IDX-CHP-1-0004" class="indexterm"/><a id="IDX-CHP-1-0005" class="indexterm"/></p><div class="sect2" title="My Preferred Techniques"><div class="titlepage"><div><div><h2 class="title"><a id="my_preferred_techniques"/>My Preferred Techniques</h2></div></div></div><p>Most of the time, I prefer the static analysis approach. I usually read the source code or disassembly of the target software line by line and try to understand it. However, reading all the code from beginning to end is generally not practical. When I’m looking for bugs, I typically start by trying to identify where user-influenced input data enters the software through an interface to the outside world. This could be network data, file data, or data from the execution environment, to name just a few examples.</p><p>Next, I study the different ways that the input data can travel through the software, while looking for any potentially exploitable code that acts on the data. Sometimes I’m able to identify these entry points solely by reading the source code (see <a class="xref" href="ch02.html" title="Chapter 2. Back to the ’90s">Chapter 2</a>) or the disassembly (see <a class="xref" href="ch06.html" title="Chapter 6. One Kernel to Rule Them All">Chapter 6</a>). In other cases, I have to combine static analysis with the results of debugging the target software (see <a class="xref" href="ch05.html" title="Chapter 5. Browse and You’re Owned">Chapter 5</a>) to find the input-handling code. I also tend to combine static and dynamic approaches when developing an exploit.</p><p>After I’ve found a bug, I want to prove if it’s actually exploitable, so I attempt to build an exploit for it. When I build such an exploit, I spend most of my time in the debugger.</p></div><div class="sect2" title="Potentially Vulnerable Code Locations"><div class="titlepage"><div><div><h2 class="title"><a id="potentially_vulnerable_code_locations"/>Potentially Vulnerable Code Locations</h2></div></div></div><p>This is only one approach to bug hunting. Another tactic for finding potentially vulnerable locations in the code is to look at the code near “unsafe” C/C++ library functions, such as <code class="literal">strcpy()</code> and <code class="literal">strcat()</code>, in search of possible buffer overflows. Alternatively, you could search the disassembly for <code class="literal">movsx</code> assembler instructions in order to find sign-extension vulnerabilities. If you find a potentially vulnerable code location, you can then trace backward through the code to see whether these code fragments expose any vulnerabilities accessible from an application entry point. I rarely use this approach, but other bug hunters swear by it.<a id="IDX-CHP-1-0006" class="indexterm"/><a id="IDX-CHP-1-0007" class="indexterm"/><a id="IDX-CHP-1-0008" class="indexterm"/></p></div><div class="sect2" title="Fuzzing"><div class="titlepage"><div><div><h2 class="title"><a id="fuzzing"/>Fuzzing</h2></div></div></div><p>A completely different approach to bug hunting is known as <span class="emphasis"><em>fuzzing</em></span>. Fuzzing is a dynamic-analysis technique that consists of testing an application by providing it with malformed or unexpected input. Though I’m not an expert in fuzzing and fuzzing frameworks—I know bug hunters who have developed their own fuzzing frameworks and find most of their bugs with their fuzzing tools—I do use this approach from time to time to determine where user-influenced input enters the software and sometimes to find bugs (see <a class="xref" href="ch08.html" title="Chapter 8. The Ringtone Massacre">Chapter 8</a>).</p><p>You may be wondering how fuzzing can be used to identify where user-influenced input enters the software. Imagine you have a complex application in the form of a binary that you want to examine for bugs. It isn’t easy to identify the entry points of such complex applications, but complex software often tends to crash while processing malformed input data. This can hold true for software that parses data files, such as office products, media players, or web browsers. Most of these crashes are not security relevant (e.g., a division-by-zero bug in a browser), but they often provide an entry point where I can start looking for user-influenced input data.</p></div><div class="sect2" title="Further Reading"><div class="titlepage"><div><div><h2 class="title"><a id="further_reading"/>Further Reading</h2></div></div></div><p>These are only a few of the available techniques and approaches that can be used to find bugs in software. For more information on finding security vulnerabilities in source code, I recommend Mark Dowd, John McDonald, and Justin Schuh’s <span class="emphasis"><em>The Art of Software Security Assessment: Identifying and Preventing Software Vulnerabilities</em></span> (Addison-Wesley, 2007). If you want more information about fuzzing, see Michael Sutton, Adam Greene, and Pedram Amini’s <span class="emphasis"><em>Fuzzing: Brute Force Vulnerability Discovery</em></span> (Addison-Wesley, 2007).</p></div></div></body></html>
